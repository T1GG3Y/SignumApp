# Complete Tech Stack for Voice Recording App

## Tech Stack Overview

### Frontend
- **React Native** - Cross-platform mobile framework
- **Expo** - Development platform for easier setup and deployment
- **React Navigation** - Navigation between screens

### Audio Recording & Storage
- **expo-av** - Audio recording and playback
- **expo-file-system** - File system access
- **@react-native-async-storage/async-storage** - Local storage

### Backend (Optional for cloud storage)
- **Firebase** or **AWS S3** - Cloud storage for recordings
- **Firebase Firestore** or **AWS DynamoDB** - Database for metadata

### UI Components
- **@expo/vector-icons** - Icon library
- **react-native-safe-area-context** - Safe area handling

## Installation & Setup

### 1. Create New Expo Project
```bash
npx create-expo-app VoiceRecordingApp
cd VoiceRecordingApp
```

### 2. Install Dependencies
```bash
npx expo install expo-av
npx expo install expo-file-system
npx expo install @react-native-async-storage/async-storage
npx expo install @expo/vector-icons
npx expo install react-native-safe-area-context
npm install @react-navigation/native @react-navigation/stack
npx expo install react-native-screens react-native-gesture-handler
```

### 3. Additional Components

#### App.js - Main Navigation
```javascript
import React from 'react';
import { NavigationContainer } from '@react-navigation/native';
import { createStackNavigator } from '@react-navigation/stack';
import RecordingScreen from './screens/RecordingScreen';
import RecordingsListScreen from './screens/RecordingsListScreen';
import PlaybackScreen from './screens/PlaybackScreen';

const Stack = createStackNavigator();

export default function App() {
  return (
    <NavigationContainer>
      <Stack.Navigator 
        initialRouteName="Recording"
        screenOptions={{
          headerShown: false,
        }}
      >
        <Stack.Screen name="Recording" component={RecordingScreen} />
        <Stack.Screen name="RecordingsList" component={RecordingsListScreen} />
        <Stack.Screen name="Playback" component={PlaybackScreen} />
      </Stack.Navigator>
    </NavigationContainer>
  );
}
```

#### RecordingsListScreen.js - View Saved Recordings
```javascript
import React, { useState, useEffect } from 'react';
import {
  View,
  Text,
  StyleSheet,
  FlatList,
  TouchableOpacity,
  SafeAreaView,
} from 'react-native';
import AsyncStorage from '@react-native-async-storage/async-storage';
import { Ionicons } from '@expo/vector-icons';

const RecordingsListScreen = ({ navigation }) => {
  const [recordings, setRecordings] = useState([]);

  useEffect(() => {
    loadRecordings();
  }, []);

  const loadRecordings = async () => {
    try {
      const savedRecordings = await AsyncStorage.getItem('recordings');
      if (savedRecordings) {
        setRecordings(JSON.parse(savedRecordings));
      }
    } catch (error) {
      console.error('Error loading recordings:', error);
    }
  };

  const formatDate = (dateString) => {
    const date = new Date(dateString);
    return date.toLocaleDateString() + ' ' + date.toLocaleTimeString();
  };

  const renderRecording = ({ item, index }) => (
    <TouchableOpacity
      style={styles.recordingItem}
      onPress={() => navigation.navigate('Playback', { recording: item })}
    >
      <View style={styles.recordingInfo}>
        <Text style={styles.questionText} numberOfLines={2}>
          {item.question}
        </Text>
        <Text style={styles.dateText}>{formatDate(item.date)}</Text>
      </View>
      <Ionicons name="play-circle" size={40} color="#3B82F6" />
    </TouchableOpacity>
  );

  return (
    <SafeAreaView style={styles.container}>
      <View style={styles.header}>
        <TouchableOpacity onPress={() => navigation.goBack()}>
          <Ionicons name="arrow-back" size={30} color="#000" />
        </TouchableOpacity>
        <Text style={styles.headerTitle}>Your Recordings</Text>
        <View style={{ width: 30 }} />
      </View>

      <FlatList
        data={recordings}
        renderItem={renderRecording}
        keyExtractor={(item, index) => index.toString()}
        contentContainerStyle={styles.listContainer}
      />
    </SafeAreaView>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#F5F5F5',
  },
  header: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    padding: 20,
    backgroundColor: '#FFFFFF',
    borderBottomWidth: 1,
    borderBottomColor: '#E5E7EB',
  },
  headerTitle: {
    fontSize: 20,
    fontWeight: '600',
  },
  listContainer: {
    padding: 20,
  },
  recordingItem: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    backgroundColor: '#FFFFFF',
    padding: 15,
    borderRadius: 10,
    marginBottom: 10,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.1,
    shadowRadius: 4,
    elevation: 3,
  },
  recordingInfo: {
    flex: 1,
    marginRight: 10,
  },
  questionText: {
    fontSize: 16,
    fontWeight: '500',
    marginBottom: 5,
  },
  dateText: {
    fontSize: 14,
    color: '#6B7280',
  },
});

export default RecordingsListScreen;
```

#### PlaybackScreen.js - Play Recordings
```javascript
import React, { useState } from 'react';
import {
  View,
  Text,
  StyleSheet,
  TouchableOpacity,
  SafeAreaView,
} from 'react-native';
import { Audio } from 'expo-av';
import { Ionicons } from '@expo/vector-icons';

const PlaybackScreen = ({ route, navigation }) => {
  const { recording } = route.params;
  const [sound, setSound] = useState(null);
  const [isPlaying, setIsPlaying] = useState(false);

  const playSound = async () => {
    try {
      const { sound } = await Audio.Sound.createAsync({ uri: recording.uri });
      setSound(sound);
      setIsPlaying(true);
      await sound.playAsync();
      
      sound.setOnPlaybackStatusUpdate((status) => {
        if (status.didJustFinish) {
          setIsPlaying(false);
        }
      });
    } catch (error) {
      console.error('Error playing sound:', error);
    }
  };

  const stopSound = async () => {
    if (sound) {
      await sound.stopAsync();
      await sound.unloadAsync();
      setSound(null);
      setIsPlaying(false);
    }
  };

  React.useEffect(() => {
    return sound
      ? () => {
          sound.unloadAsync();
        }
      : undefined;
  }, [sound]);

  return (
    <SafeAreaView style={styles.container}>
      <View style={styles.header}>
        <TouchableOpacity onPress={() => navigation.goBack()}>
          <Ionicons name="arrow-back" size={30} color="#000" />
        </TouchableOpacity>
        <Text style={styles.headerTitle}>Playback</Text>
        <View style={{ width: 30 }} />
      </View>

      <View style={styles.content}>
        <Text style={styles.questionText}>{recording.question}</Text>
        <Text style={styles.dateText}>
          Recorded on: {new Date(recording.date).toLocaleString()}
        </Text>

        <TouchableOpacity
          style={[styles.playButton, isPlaying && styles.stopButton]}
          onPress={isPlaying ? stopSound : playSound}
        >
          <Ionicons
            name={isPlaying ? 'stop' : 'play'}
            size={40}
            color="#FFFFFF"
          />
        </TouchableOpacity>
      </View>
    </SafeAreaView>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#F5F5F5',
  },
  header: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    padding: 20,
    backgroundColor: '#FFFFFF',
    borderBottomWidth: 1,
    borderBottomColor: '#E5E7EB',
  },
  headerTitle: {
    fontSize: 20,
    fontWeight: '600',
  },
  content: {
    flex: 1,
    padding: 20,
    alignItems: 'center',
    justifyContent: 'center',
  },
  questionText: {
    fontSize: 18,
    textAlign: 'center',
    marginBottom: 20,
    paddingHorizontal: 20,
    lineHeight: 28,
  },
  dateText: {
    fontSize: 16,
    color: '#6B7280',
    marginBottom: 40,
  },
  playButton: {
    width: 80,
    height: 80,
    borderRadius: 40,
    backgroundColor: '#3B82F6',
    justifyContent: 'center',
    alignItems: 'center',
  },
  stopButton: {
    backgroundColor: '#EF4444',
  },
});

export default PlaybackScreen;
```

## Cloud Storage Integration (Optional)

### Firebase Setup
```javascript
// firebase.js
import { initializeApp } from 'firebase/app';
import { getStorage } from 'firebase/storage';
import { getFirestore } from 'firebase/firestore';

const firebaseConfig = {
  // Your Firebase config
};

const app = initializeApp(firebaseConfig);
export const storage = getStorage(app);
export const db = getFirestore(app);

// Upload recording to Firebase Storage
import { ref, uploadBytes, getDownloadURL } from 'firebase/storage';
import { collection, addDoc } from 'firebase/firestore';

const uploadRecording = async (uri, metadata) => {
  const response = await fetch(uri);
  const blob = await response.blob();
  
  const storageRef = ref(storage, `recordings/${Date.now()}.m4a`);
  const snapshot = await uploadBytes(storageRef, blob);
  const downloadURL = await getDownloadURL(snapshot.ref);
  
  // Save metadata to Firestore
  await addDoc(collection(db, 'recordings'), {
    ...metadata,
    url: downloadURL,
    createdAt: new Date(),
  });
};
```

## Additional Features to Consider

1. **User Authentication** - Add login/signup screens
2. **Question Categories** - Organize questions by themes
3. **Daily Reminders** - Push notifications for daily check-ins
4. **Analytics** - Track mood/energy patterns over time
5. **Export Feature** - Export recordings as audio files
6. **Transcription** - Use speech-to-text APIs for text versions

## App Permissions (app.json)
```json
{
  "expo": {
    "name": "VoiceRecordingApp",
    "slug": "voice-recording-app",
    "version": "1.0.0",
    "orientation": "portrait",
    "icon": "./assets/icon.png",
    "plugins": [
      [
        "expo-av",
        {
          "microphonePermission": "Allow $(PRODUCT_NAME) to access your microphone to record your daily reflections."
        }
      ]
    ]
  }
}
```

## Deployment

### iOS
```bash
expo build:ios
```

### Android
```bash
expo build:android
```

## Performance Optimization Tips

1. **Compress Audio Files** - Use lower quality settings for smaller file sizes
2. **Pagination** - Load recordings in batches for better performance
3. **Cache Management** - Clear old recordings periodically
4. **Background Audio** - Enable background audio recording capability

This tech stack provides a solid foundation for your voice recording app with local storage. You can extend it with cloud features as needed.